Social media platform, Facebook, has said 89 per cent of hate speech are being detected and deleted by it before complaints arise. Besides, it said actions taken on suicide and self-injury contents increased by 40 per cent, adding that some 8.8 million drug-related posts were obliterated earlier in the year, doubling the figure of the last quarter of 2009. The technology company made the revelations yesterday while releasing its May 2020 Community Standards Enforcement Report. Unveiling the document in a newsroom post, the Vice President, Integrity, Guy Rosen, said the organisation had in the last few years built tools, teams and technologies to protect electoral interference, spread of misinformation safeguard against harm. He said: “So when the COVID-19 crisis emerged, we had the tools and processes in place to move quickly, and we were able to continue finding and removing content that violates our policies. When we temporarily sent our content reviewers home due to the COVID-19 pandemic, we increased our reliance on these automated systems and prioritised high-severity content for our teams to review in order to continue to keep our apps safe during this time.” The report, Rosen added, includes only data for the period, and does not reflect the full impact of the changes the company made during the pandemic. The official went on: “We anticipate we’ll see the impact of those changes in our next report, and possibly beyond, and we will be transparent about them. For example, for the past seven weeks, we couldn’t always offer the option to appeal content decisions and account removals, so we expect the number of appeals to be much lower in our next report. “We also prioritised removing harmful content over measuring our efforts, so we may not be able to calculate the prevalence of violating content during this time. Today’s report shows the impact of advancements we’ve made in the technology we use to proactively find and remove violating content.” Furthermore, he said the platform expanded its proactive detection technology for hate speech to more languages, and improved existing detection systems. On Instagram, the vice president pointed out that Facebook made “improvements to our text and image matching technology to help find more suicide and self-injury contents.” He submitted that the advancements in technology “for finding and removing content similar to existing violations in our databases helped the company take down more child nudity and sexual exploitative contents on Facebook and Instagram.” Over the last six months, Rosen said Facebook had deplored more technology to prioritise content for its teams to review based on factors like virality and severity, among others.  To enable commenting and other interactive features, please switch to the more advanced .